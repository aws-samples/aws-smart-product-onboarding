{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70fc2704-b80f-4872-a911-4357eef2f254",
   "metadata": {},
   "source": [
    "# Metaclasses Generation from Category Tree and Language Adaptiation\n",
    "This notebook guides you through the process of generating metaclasses for product categorization and adapting the system for different languages. We'll be preparing the necessary data structures to configure the `TextCleaner` class, which is used both in this notebook and in the production system.\n",
    "\n",
    "The process is iterative: we'll start with initial data structures, analyze the category tree, and then refine our configurations based on the results.\n",
    "\n",
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.<br>\n",
    "SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e10d7dd4e7893",
   "metadata": {},
   "source": [
    "## Process Overview\n",
    "\n",
    "This notebook follows a structured process to prepare and analyze category data:\n",
    "\n",
    "1. Load and analyze the category tree\n",
    "2. Prepare and refine text cleaning configurations\n",
    "3. Clean and analyze category names\n",
    "4. Generate and analyze word embeddings\n",
    "5. Identify special categories (like media)\n",
    "6. Adapt the process for different languages (optional)\n",
    "7. Persist the prepared data for use in production\n",
    "\n",
    "Each step builds on the previous ones, creating a robust foundation for product categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa11568-4e16-4854-b479-a81bc53fa2e7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Prerequisites\n",
    "The IAM user or role used by this notebook needs access to Amazon S3 and AWS Systems Manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a1d03-05c0-4690-bf5f-e0de90b75fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T13:52:51.899489Z",
     "start_time": "2025-02-10T13:52:51.803175Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "import boto3\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "from mypy_boto3_ssm import SSMClient\n",
    "from mypy_boto3_dynamodb import DynamoDBClient, DynamoDBServiceResource\n",
    "from mypy_boto3_bedrock_runtime import BedrockRuntimeClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce55a3e7ff9584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:51:12.668614Z",
     "start_time": "2025-01-31T18:51:11.701646Z"
    }
   },
   "outputs": [],
   "source": [
    "ssm: SSMClient = boto3.client('ssm')\n",
    "ddb: DynamoDBClient = boto3.client('dynamodb')\n",
    "ddbr: DynamoDBServiceResource = boto3.resource('dynamodb')\n",
    "bedrock: BedrockRuntimeClient = boto3.client('bedrock-runtime')\n",
    "iam = boto3.client('iam')\n",
    "ssm_prefix = '/ProductCategorization/'\n",
    "vector_table_prefix = \"SmartProductOnboarding-\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df2ddf21d504fc",
   "metadata": {},
   "source": [
    "## Load and Analyze the Category Tree\n",
    "\n",
    "First, let's load our category data and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826048f6-e479-41a4-b200-86cf245e87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1afb8c5dee9d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:44:51.091201Z",
     "start_time": "2024-12-08T20:44:51.053891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load category data\n",
    "with open(\"data/labelcats.json\", \"r\") as f:\n",
    "    category_tree = json.load(f)\n",
    "\n",
    "\n",
    "# Function to get leaf categories\n",
    "def get_leaf_categories(cat_tree):\n",
    "    leaf_categories = []\n",
    "    for cat_id in cat_tree:\n",
    "        if cat_id == 'root':\n",
    "            continue\n",
    "        category = cat_tree[cat_id]\n",
    "        if len(category.get('childs', [])) <= 0:\n",
    "            leaf_categories.append({\n",
    "                'name': category['name'],\n",
    "                'id': category['id'],\n",
    "                'description': category['description']\n",
    "            })\n",
    "    return leaf_categories\n",
    "\n",
    "\n",
    "leaf_categories = get_leaf_categories(category_tree)\n",
    "leaf_df = pd.DataFrame(leaf_categories)\n",
    "\n",
    "print(f\"Total leaf categories: {len(leaf_df)}\")\n",
    "leaf_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ff7294a84fac4",
   "metadata": {},
   "source": [
    "### Text Refinement Preparation\n",
    "\n",
    "Before we start processing our category data, we need to set up some initial data structures. These structures are crucial for effective text cleaning and categorization:\n",
    "\n",
    "- Singularization exceptions: Words that don't follow standard singularization rules\n",
    "- Descriptors: Common words that don't help differentiate categories\n",
    "- Brands: Brand names that should be excluded from category analysis\n",
    "- Synonyms: Alternative terms for the same concept\n",
    "\n",
    "These structures help ensure that our text cleaning process is accurate and that we're focusing on the most meaningful words in our category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca239e0db2f64bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial singularization exceptions\n",
    "singularize_exceptions = {\n",
    "    \"clothes\": \"clothes\",\n",
    "    \"canvas\": \"canvas\",\n",
    "    \"fruticosus\": \"fruticosus\",\n",
    "    \"dies\": \"die\",\n",
    "    \"lotus\": \"lotus\",\n",
    "    \"tinctorius\": \"tinctorius\",\n",
    "    \"gymnastics\": \"gymnastics\",\n",
    "    \"mollis\": \"mollis\",\n",
    "    \"myosotis\": \"myosotis\",\n",
    "    \"australis\": \"australis\",\n",
    "    \"gas\": \"gas\",\n",
    "    \"gps\": \"gps\",\n",
    "    \"guatemalensis\": \"guatemalensis\",\n",
    "    \"elegans\": \"elegans\",\n",
    "    \"christmas\": \"christmas\",\n",
    "    \"cosmos\": \"cosmos\",\n",
    "    \"xps\": \"xps\",\n",
    "    \"muralis\": \"muralis\",\n",
    "    \"narcissus\": \"narcissus\",\n",
    "    \"barbatus\": \"barbatus\",\n",
    "    \"cactus\": \"cactus\",\n",
    "    \"hibiscus\": \"hibiscus\",\n",
    "    \"callus\": \"callus\",\n",
    "    \"cycas\": \"cycas\",\n",
    "    \"prunus\": \"prunus\",\n",
    "    \"overalls\": \"overalls\",\n",
    "    \"nitrous\": \"nitrous\",\n",
    "    \"bellis\": \"bellis\",\n",
    "    \"coreopsis\": \"coreopsis\",\n",
    "    \"iris\": \"iris\",\n",
    "    \"erinus\": \"erinus\",\n",
    "    \"plectranthus\": \"plectranthus\",\n",
    "    \"euryops\": \"euryops\",\n",
    "    \"hyacinthus\": \"hyacinthus\",\n",
    "    \"rhipsalidopsis\": \"rhipsalidopsis\",\n",
    "    \"cos\": \"cos\",\n",
    "    \"orientalis\": \"orientalis\",\n",
    "    \"annuus\": \"annuus\",\n",
    "    \"lotononis\": \"lotononis\",\n",
    "    \"sylvestris\": \"sylvestris\",\n",
    "    \"argus\": \"argus\",\n",
    "    \"sinensis\": \"sinensis\",\n",
    "    \"crocus\": \"crocus\",\n",
    "    \"corylus\": \"corylus\",\n",
    "    \"edulis\": \"edulis\",\n",
    "    \"paris\": \"paris\",\n",
    "    \"helianthus\": \"helianthus\",\n",
    "    \"orchis\": \"orchis\",\n",
    "    \"zamioculcas\": \"zamioculcas\",\n",
    "    \"psoriasis\": \"psoriasis\",\n",
    "    \"stylus\": \"stylus\",\n",
    "    \"abies\": \"abies\",\n",
    "    \"cupressus\": \"cupressus\",\n",
    "    \"grandis\": \"grandis\",\n",
    "    \"hupehensis\": \"hupehensis\",\n",
    "    \"pinus\": \"pinus\",\n",
    "    \"cannabis\": \"cannabis\",\n",
    "    \"cucumis\": \"cucumis\",\n",
    "    \"ficus\": \"ficus\",\n",
    "    \"physalis\": \"physalis\",\n",
    "    \"corniculatus\": \"corniculatus\",\n",
    "    \"dypsis\": \"dypsis\",\n",
    "    \"vulgaris\": \"vulgaris\",\n",
    "    \"nephrolepis\": \"nephrolepis\",\n",
    "    \"gracilis\": \"gracilis\",\n",
    "    \"asiaticus\": \"asiaticus\",\n",
    "    \"babacos\": \"babacos\",\n",
    "    \"helleborus\": \"helleborus\",\n",
    "    \"lupinus\": \"lupinus\",\n",
    "    \"rhapis\": \"rhapis\",\n",
    "    \"cyperus\": \"cyperus\",\n",
    "    \"ruscus\": \"ruscus\",\n",
    "    \"opulus\": \"opulus\",\n",
    "    \"lutescens\": \"lutescens\",\n",
    "    \"perennis\": \"perennis\",\n",
    "    \"index\": \"index,\"\n",
    "}\n",
    "\n",
    "# Initial descriptors (common words that don't help differentiate categories)\n",
    "descriptors = [\n",
    "    \"accessory\",\n",
    "    \"live\",\n",
    "    \"part\",\n",
    "    \"replacement\",\n",
    "    \"equipment\",\n",
    "    \"product\",\n",
    "    \"cut\",\n",
    "    \"ready\",\n",
    "    \"prepared\",\n",
    "    \"processed\",\n",
    "    \"unprepared\",\n",
    "    \"unprocessed\",\n",
    "    \"sport\",\n",
    "    \"baby\",\n",
    "    \"garden\",\n",
    "    \"non\",\n",
    "    \"kit\",\n",
    "    \"set\",\n",
    "    \"pack\",\n",
    "]\n",
    "\n",
    "# List the brands in your store. If any brand names are dictionary words, they should not be included here.\n",
    "brands = []\n",
    "\n",
    "# Initial synonyms (regional variations, etc.)\n",
    "# For English, this might be empty or contain British/American variations\n",
    "synonyms = {\n",
    "    \"sneaker\": \"shoe\",\n",
    "}\n",
    "\n",
    "print(\"Initial data structures prepared.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d240d682bc6ba",
   "metadata": {},
   "source": [
    "### TextCleaner Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690b3bae62d5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will be re-run after refinements\n",
    "def instantiate_text_cleaner():\n",
    "    from amzn_smart_product_onboarding_metaclasses.text_cleaner import TextCleaner\n",
    "\n",
    "    return TextCleaner(\n",
    "        singularize=singularize_exceptions,\n",
    "        brands=brands,\n",
    "        synonyms=synonyms,\n",
    "        descriptors=descriptors,\n",
    "        language=\"english\"  # or your target language\n",
    "    )\n",
    "\n",
    "\n",
    "text_cleaner = instantiate_text_cleaner()\n",
    "print(\"TextCleaner instantiated with current data structures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d47e3505f84c",
   "metadata": {},
   "source": [
    "### Category Name Analysis\n",
    "\n",
    "In this section, we'll clean our category names and analyze the results. This analysis helps us:\n",
    "\n",
    "1. Identify common words across categories\n",
    "2. Spot potential new descriptors (words that appear frequently but don't differentiate categories)\n",
    "3. Ensure our cleaning process is working as expected\n",
    "\n",
    "By iterating on this analysis, we can refine our text cleaning process and improve our understanding of the category structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09b2e4d847b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will be re-run after refinements\n",
    "def analyze_category_names(df):\n",
    "    # Clean category names using TextCleaner\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df['clean_name'] = cleaned_df['name'].apply(text_cleaner.clean_text)\n",
    "    cleaned_df = cleaned_df.dropna()\n",
    "\n",
    "    # Tokenize and count words in cleaned category names\n",
    "    all_words = ' '.join(cleaned_df['clean_name']).split()\n",
    "    word_counts = Counter(all_words)\n",
    "\n",
    "    print(\"Most common words in cleaned category names:\")\n",
    "    print(word_counts.most_common(20))\n",
    "\n",
    "    # Identify potential new descriptors (words that appear in many categories)\n",
    "    potential_new_descriptors = [word for word, count in word_counts.items()\n",
    "                                 if count > len(cleaned_df) * 0.05 and word not in descriptors]\n",
    "    print(\"\\nPotential new descriptors to consider:\")\n",
    "    print(potential_new_descriptors)\n",
    "\n",
    "    # Display sample of cleaned names\n",
    "    print(\"\\nSample of cleaned category names:\")\n",
    "    print(cleaned_df[['name', 'clean_name']].head())\n",
    "\n",
    "    # Return the new dataframe\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "cleaned_leaf_df = analyze_category_names(leaf_df)\n",
    "cleaned_leaf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d092a60ce80a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_df = cleaned_leaf_df[[\"clean_name\", \"id\"]].rename(columns={\"clean_name\": \"name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c68fe64d4a3428",
   "metadata": {},
   "source": [
    "#### Refinement Process\n",
    "If there are any words above that are in many categories, consider adding them to the list of descriptors in `Text Refinement Preparation` and re-run the `TextCleaner` and `Category Name Analysis` steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada77d774f9653b",
   "metadata": {},
   "source": [
    "### Word Frequency Analysis\n",
    "\n",
    "Understanding the frequency of words in our cleaned category names provides valuable insights:\n",
    "\n",
    "1. It helps identify terms that are central to our category structure\n",
    "2. It can reveal potential issues in our cleaning process (e.g., if very common words aren't being removed as expected)\n",
    "3. It guides the refinement of our descriptor list and other cleaning parameters\n",
    "\n",
    "This analysis is crucial for optimizing our categorization process and ensuring we're focusing on the most meaningful terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70667954f60e27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_word_frequency(df):\n",
    "    word_freq_df = pd.DataFrame(df['clean_name'].str.split(expand=True).stack().value_counts()).reset_index()\n",
    "    word_freq_df.columns = ['word', 'frequency']\n",
    "    word_freq_df['percentage'] = word_freq_df['frequency'] / len(df) * 100\n",
    "    return word_freq_df\n",
    "\n",
    "\n",
    "word_freq_df = analyze_word_frequency(cleaned_leaf_df)\n",
    "print(\"Word frequency analysis:\")\n",
    "word_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80a015d03e1bdb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "word_map = {}\n",
    "n = 0\n",
    "for _, cat in cleaned_leaf_df.iterrows():\n",
    "    for word in cat['clean_name'].split():\n",
    "        if word == '' or word == ' ' or word == 'other':\n",
    "            n += 1\n",
    "            continue\n",
    "        if word not in word_map:\n",
    "            word_map[word] = {cat['id']}\n",
    "        else:\n",
    "            word_map[word].add(cat['id'])\n",
    "\n",
    "unique_count_df = pd.DataFrame([{'word': k, 'count': len(v)} for k, v in word_map.items()])\n",
    "\n",
    "print(f'Total of \"Other\" {n}')\n",
    "print(f'Unique leaf category words {len(word_map)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f36f6742b2a1e80",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unique_leaves = {}\n",
    "unique_leaves_list = []\n",
    "n = 0\n",
    "for word in cleaned_leaf_df['clean_name']:\n",
    "    if word == '' or word == ' ' or word == 'other':\n",
    "        n += 1\n",
    "        continue\n",
    "    if word not in unique_leaves:\n",
    "        unique_leaves[word] = 1\n",
    "        unique_leaves_list.append(word)\n",
    "    else:\n",
    "        unique_leaves[word] += 1\n",
    "print(f'Total of \"Other\" {n}')\n",
    "print(f'Unique leaf category names {len(unique_leaves)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a70c822711a54",
   "metadata": {},
   "source": [
    "## Vector Embeddings\n",
    "\n",
    "While exact word matches are our primary method for categorization, vector embeddings provide a powerful complement:\n",
    "\n",
    "1. They allow us to find similar words, helping with synonyms and related terms\n",
    "2. They can capture semantic relationships that aren't apparent from exact matches alone\n",
    "3. They're especially useful for handling nuanced or ambiguous category names\n",
    "\n",
    "By combining exact matches with vector-based similarity, we create a more robust and flexible categorization system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149056b26a0dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chilean Spanish Embeddings\n",
    "#EMBEDDINGS_MODEL_URL=\"https://zenodo.org/records/3255001/files/embeddings-l-model.vec\"\n",
    "\n",
    "#English Embeddings\n",
    "DEFAULT_EMBEDDINGS_MODEL_URL = (\"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\", \"bb43875cfae187e8cef0be558a1851fb1c62daca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2b1e39d4ed393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import gzip\n",
    "from decimal import Decimal\n",
    "from amazon.ion import simpleion\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaef4f35300b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def secure_download(url, destination):\n",
    "    # Parse the URL to extract the hostname\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    # Check if the URL uses HTTPS\n",
    "    if parsed_url.scheme != 'https':\n",
    "        raise ValueError(\"URL must use HTTPS\")\n",
    "\n",
    "    # Perform the request with a timeout and verify SSL certificates\n",
    "    response = requests.get(url, timeout=30, verify=True, stream=True)\n",
    "\n",
    "    # Raise an exception for bad status codes\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Write the content to the file\n",
    "    with open(destination, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4b99b-8847-44e6-a6f8-bcd3909dbe0d",
   "metadata": {},
   "source": [
    "This next step may take a long time while downloading and loading the vectors file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad4599-6880-4375-8871-8d1973b003ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_generator(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    count = 0\n",
    "    for line in fin:\n",
    "        if count % 100000 == 0:\n",
    "            print(f\"{count}/{n}\")\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        word: str = tokens[0]\n",
    "        if word.isalpha():\n",
    "            yield {\n",
    "                \"Item\": {\n",
    "                    \"word\": word,\n",
    "                    \"vector\": list(map(Decimal, tokens[1:]))\n",
    "                }\n",
    "            }\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6116a-954c-4ec1-a1a6-0782cd62efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_models(model_urls):\n",
    "    files = []\n",
    "    for model_url in model_urls:\n",
    "        (url, checksum) = model_url if type(model_url) == \"tuple\" else (model_url, \"0\")\n",
    "        vecfile_basename = os.path.basename(url)\n",
    "        should_download = True\n",
    "        if os.path.exists(os.path.join(\"data\", vecfile_basename)):\n",
    "            with open(os.path.join(\"data\", vecfile_basename), \"rb\", buffering=0) as f:\n",
    "                sha1 = hashlib.file_digest(f, 'sha1').hexdigest()\n",
    "            if checksum == sha1:\n",
    "                should_download = False\n",
    "        if should_download:\n",
    "            secure_download(url, os.path.join(\"data\", vecfile_basename))\n",
    "            with open(os.path.join(\"data\", vecfile_basename), \"rb\", buffering=0) as f:\n",
    "                sha1 = hashlib.file_digest(f, 'sha1').hexdigest()\n",
    "            print(url, sha1)\n",
    "        if vecfile_basename.endswith('.zip'):\n",
    "            print(f'Extracting embeddings {url}')\n",
    "            with zipfile.ZipFile(os.path.join(\"data\", vecfile_basename), 'r') as zip_ref:\n",
    "                zip_ref.extractall(\"data\")\n",
    "            print(f'Extracted embeddings {url}')\n",
    "            files.append(os.path.join(\"data\", vecfile_basename.replace('.zip', '')))\n",
    "        elif vecfile_basename.endswith('.vec'):\n",
    "            files.append(os.path.join(\"data\", vecfile_basename))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef3af0-98ea-4156-8a34-e2cdc7115fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 0\n",
    "vectors_fobj = gzip.open(f\"data/english_vectors_import/vectors_{file_idx}.ion.gz\", \"wb\")\n",
    "batch = []\n",
    "count = 0\n",
    "for model in get_embeddings_models([DEFAULT_EMBEDDINGS_MODEL_URL]):\n",
    "    for item in vector_generator(model):\n",
    "        batch.append(item)\n",
    "        if len(batch) >= 1_000:\n",
    "            simpleion.dump(batch, vectors_fobj, binary=True, sequence_as_stream=True)\n",
    "            count += len(batch)\n",
    "            batch = []\n",
    "        if count >= 100_000:\n",
    "            vectors_fobj.close()\n",
    "            file_idx += 1\n",
    "            vectors_fobj = gzip.open(f\"data/english_vectors_import/vectors_{file_idx}.ion.gz\", \"wb\")\n",
    "            count = 0\n",
    "if batch:\n",
    "    simpleion.dump(batch, vectors_fobj, binary=True, sequence_as_stream=True)\n",
    "vectors_fobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d11c8-7267-4476-87fa-e3f5ca50e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync data/english_vectors_import/ s3://aws-strunkjd-tmp-use1/english_vectors_import/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb49503-db4f-41cd-b5e6-82264c606a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_table_name = vector_table_prefix + \"english_vectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71496bbe-dbab-4a4f-a429-fd94e3ce7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = ddb.import_table(\n",
    "    S3BucketSource={\n",
    "        \"S3Bucket\": \"aws-strunkjd-tmp-use1\",\n",
    "        \"S3KeyPrefix\": \"english_vectors_import\",\n",
    "    },\n",
    "    InputFormat=\"ION\",\n",
    "    InputCompressionType=\"GZIP\",\n",
    "    TableCreationParameters={\n",
    "        'TableName': vector_table_name,\n",
    "        'AttributeDefinitions': [\n",
    "            {\n",
    "                'AttributeName': 'word',\n",
    "                'AttributeType': 'S'\n",
    "            },\n",
    "        ],\n",
    "        'KeySchema': [\n",
    "            {\n",
    "                'AttributeName': 'word',\n",
    "                'KeyType': 'HASH'\n",
    "            },\n",
    "        ],\n",
    "        'BillingMode': 'PAY_PER_REQUEST',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb1884-d45f-4b64-9a57-97cc64ac93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_status = ddb.describe_import(ImportArn=job[\"ImportTableDescription\"][\"ImportArn\"])\n",
    "while job_status[\"ImportTableDescription\"][\"ImportStatus\"] == 'IN_PROGRESS':\n",
    "    time.sleep(60)\n",
    "    print(job_status[\"ImportTableDescription\"][\"ImportStatus\"])\n",
    "    job_status = ddb.describe_import(ImportArn=job[\"ImportTableDescription\"][\"ImportArn\"])\n",
    "\n",
    "job_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1adfbb-97b9-4694-9957-d9b71b320453",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_table = ddbr.Table(vector_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20885fab-5984-4e9a-bd32-42eaf69e7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vectors = {}\n",
    "batch = []\n",
    "for w in word_map.keys():\n",
    "    batch.append(w)  \n",
    "    if len(batch) > 100:\n",
    "        raise Exception(\"max batch size is 100\")\n",
    "    elif len(batch) == 100:\n",
    "        result = ddb.batch_get_item(\n",
    "            RequestItems={\n",
    "                vector_table_name: {\n",
    "                    \"Keys\": [{\n",
    "                        \"word\": {\n",
    "                            \"S\": word,\n",
    "                        }\n",
    "                    } for word in batch]\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "        for item in result['Responses'][vector_table_name]:\n",
    "            word = item['word']['S']\n",
    "            vector = []\n",
    "            for v in item['vector']['L']:\n",
    "                vector.append(float(v['N']))\n",
    "            category_vectors[word] = vector\n",
    "        batch = []\n",
    "if batch:\n",
    "    result = ddb.batch_get_item(\n",
    "        RequestItems={\n",
    "            vector_table_name: {\n",
    "                \"Keys\": [{\n",
    "                    \"word\": {\n",
    "                        \"S\": word,\n",
    "                    }\n",
    "                } for word in batch]\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    for item in result['Responses'][vector_table_name]:\n",
    "        word = item['word']['S']\n",
    "        vector = []\n",
    "        for v in item['vector']['L']:\n",
    "            vector.append(float(v['N']))\n",
    "        category_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb034361a65167a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"wordvectors contains {len(category_vectors)}/{len(word_map)} category words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fdf8e-8719-4c7c-afd7-be11f9453259",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = list(category_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c015b-2dc0-4c3d-90f2-b9ee486afbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(next(iter(category_vectors.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabafbc3-69fc-4fab-8a81-3a4aef619f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29257375-e3ce-4a93-8efc-2db5235c438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.index_factory(d, \"Flat\", faiss.METRIC_INNER_PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a3cec-f18f-40de-b22b-3ef2a2f0a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_array = np.array([v for v in category_vectors.values()]).astype(np.float32)\n",
    "faiss.normalize_L2(index_array)\n",
    "index.add(index_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32b64b-612f-4949-a8f8-2e454eb033e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0b305-da97-4c2a-8cf9-170111388bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = np.array([np.array(category_vectors[\"shirt\"]).astype(np.float32)])\n",
    "faiss.normalize_L2(sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0af77-f82a-4a34-9a85-c0eb5657dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20300437-8bbf-41f1-a2c3-c476c28baa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(sv, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc1e1a-472f-4722-86b4-a0d535c5abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance, idx in zip(D[0],I[0]):\n",
    "    print(f\"{word_index[idx]}: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d150cf9-41b9-4f2b-8c86-31b968aff198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(table: DynamoDBServiceResource.Table, word: str) -> np.ndarray:\n",
    "    response = table.get_item(Key={\"word\": word})\n",
    "    if \"Item\" not in response:\n",
    "        raise KeyError(f\"No embedding for {word}\")\n",
    "    vector = response[\"Item\"][\"vector\"]\n",
    "    sv = np.array([list(map(float, vector))]).astype(np.float32)\n",
    "    faiss.normalize_L2(sv)\n",
    "    return sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b8a8e-5254-468b-a33a-e2813c39c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = get_word_embeddings(vector_table, \"jersey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2abd6-00a3-425a-970a-8f96630ae865",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(sv, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed8658-ffbb-4408-9e1b-2346ebfb444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance, idx in zip(D[0],I[0]):\n",
    "    print(f\"{word_index[idx]}: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09040652-6e58-488c-b9ac-62332aea0060",
   "metadata": {},
   "source": [
    "### Grant read access to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfcd84-c349-4ef6-9ecb-cc674d122fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_policy_arn = ssm.get_parameter(Name=f\"{ssm_prefix}WordEmbeddingsPolicyArn\")['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b31a49-5688-453d-8c01-2b2eec38aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.create_policy_version(\n",
    "    PolicyArn=word_embeddings_policy_arn,\n",
    "    PolicyDocument=json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "            \"Sid\": \"wordembeddings\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                    \"dynamodb:GetItem\",\n",
    "                    \"dynamodb:BatchGetItem\",\n",
    "                    \"dynamodb:Scan\",\n",
    "                    \"dynamodb:Query\",\n",
    "                    \"dynamodb:ConditionCheckItem\"\n",
    "                ],\n",
    "            \"Resource\": vector_table.table_arn,\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    SetAsDefault=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5860a1b-704b-4e89-8939-2c58c46d9c09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## OPTIONAL Experiment: Using aligned vectors for multilingual metaclass identification\n",
    "We should be able to use aligned word vectors to find metaclass words across languages.\n",
    "\n",
    "In our experimentation it did not work, but this may work with better word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f464c-88aa-43ee-b743-c2dc530b1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add aligned vectors for your desired languages from https://fasttext.cc/docs/en/aligned-vectors.html\n",
    "ALIGNED_EMBEDDINGS_MODEL_URLS = [\n",
    "    (\"https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.en.align.vec\", \"a3ca1fd0beaf3e99ef1c911cc256306286934860\"),\n",
    "    (\"https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.es.align.vec\", \"98254cb84228ce452f30f1444576fbce756e65d5\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84df4be-32ca-431a-a012-5ef69c3f2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx = 0\n",
    "vectors_fobj = gzip.open(f\"data/aligned_vectors_import/vectors_{file_idx}.ion.gz\", \"wb\")\n",
    "batch = []\n",
    "count = 0\n",
    "for model in get_embeddings_models([ALIGNED_EMBEDDINGS_MODEL_URLS]):\n",
    "    for item in vector_generator(model):\n",
    "        batch.append(item)\n",
    "        if len(batch) >= 1_000:\n",
    "            simpleion.dump(batch, vectors_fobj, binary=True, sequence_as_stream=True)\n",
    "            count += len(batch)\n",
    "            batch = []\n",
    "        if count >= 100_000:\n",
    "            vectors_fobj.close()\n",
    "            file_idx += 1\n",
    "            vectors_fobj = gzip.open(f\"data/aligned_vectors_import/vectors_{file_idx}.ion.gz\", \"wb\")\n",
    "            count = 0\n",
    "if batch:\n",
    "    simpleion.dump(batch, vectors_fobj, binary=True, sequence_as_stream=True)\n",
    "vectors_fobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fe8bd-5291-4f54-9e2e-f05b047a5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync data/aligned_vectors_import/ s3://aws-strunkjd-tmp-use1/aligned_vectors_import/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b094ba2-7124-4e5e-af41-2a8dbc146ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_vector_table_name = \"aligned_vectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890f97a-4fd3-47cb-b905-4053dcf136a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = ddb.import_table(\n",
    "    S3BucketSource={\n",
    "        \"S3Bucket\": \"aws-strunkjd-tmp-use1\",\n",
    "        \"S3KeyPrefix\": \"aligned_vectors_import\",\n",
    "    },\n",
    "    InputFormat=\"ION\",\n",
    "    InputCompressionType=\"GZIP\",\n",
    "    TableCreationParameters={\n",
    "        'TableName': aligned_vector_table_name,\n",
    "        'AttributeDefinitions': [\n",
    "            {\n",
    "                'AttributeName': 'word',\n",
    "                'AttributeType': 'S'\n",
    "            },\n",
    "        ],\n",
    "        'KeySchema': [\n",
    "            {\n",
    "                'AttributeName': 'word',\n",
    "                'KeyType': 'HASH'\n",
    "            },\n",
    "        ],\n",
    "        'BillingMode': 'PAY_PER_REQUEST',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac11e66c-6baf-475d-8456-bda63f775d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_status = ddb.describe_import(ImportArn=job[\"ImportTableDescription\"][\"ImportArn\"])\n",
    "while job_status[\"ImportTableDescription\"][\"ImportStatus\"] == 'IN_PROGRESS':\n",
    "    time.sleep(60)\n",
    "    print(job_status[\"ImportTableDescription\"][\"ImportStatus\"])\n",
    "    job_status = ddb.describe_import(ImportArn=job[\"ImportTableDescription\"][\"ImportArn\"])\n",
    "\n",
    "job_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66c927-864d-4026-9faa-f4798a7423e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_vector_table = ddbr.Table(aligned_vector_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110617c-80b5-4d59-aaf9-3869c0cf2ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_category_vectors = {}\n",
    "batch = []\n",
    "for w in word_map.keys():\n",
    "    batch.append(w)  \n",
    "    if len(batch) > 100:\n",
    "        raise Exception(\"max batch size is 100\")\n",
    "    elif len(batch) == 100:\n",
    "        result = ddb.batch_get_item(\n",
    "            RequestItems={\n",
    "                aligned_vector_table_name: {\n",
    "                    \"Keys\": [{\n",
    "                        \"word\": {\n",
    "                            \"S\": word,\n",
    "                        }\n",
    "                    } for word in batch]\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "        for item in result['Responses'][aligned_vector_table_name]:\n",
    "            word = item['word']['S']\n",
    "            vector = []\n",
    "            for v in item['vector']['L']:\n",
    "                vector.append(float(v['N']))\n",
    "            aligned_category_vectors[word] = vector\n",
    "        batch = []\n",
    "if batch:\n",
    "    result = ddb.batch_get_item(\n",
    "        RequestItems={\n",
    "            aligned_vector_table_name: {\n",
    "                \"Keys\": [{\n",
    "                    \"word\": {\n",
    "                        \"S\": word,\n",
    "                    }\n",
    "                } for word in batch]\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    for item in result['Responses'][aligned_vector_table_name]:\n",
    "        word = item['word']['S']\n",
    "        vector = []\n",
    "        for v in item['vector']['L']:\n",
    "            vector.append(float(v['N']))\n",
    "        aligned_category_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137135d-fbc2-4b93-b667-09bd3e12a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"wordvectors contains {len(aligned_category_vectors)}/{len(word_map)} category words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa1cc1-cfce-483c-af1a-e506988da1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_word_index = list(aligned_category_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078c091-39cf-41e9-9092-bee59a0b8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(next(iter(aligned_category_vectors.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1060d-ef79-4051-afd2-98de0979aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededbf1f-15d1-47c0-9eff-739871d414ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_index = faiss.index_factory(d, \"Flat\", faiss.METRIC_INNER_PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a050729-2593-47e4-8015-b1b6eef74941",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_index_array = np.array([v for v in aligned_category_vectors.values()]).astype(np.float32)\n",
    "faiss.normalize_L2(aligned_index_array)\n",
    "aligned_index.add(aligned_index_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4d0cb-78b8-46ce-85b5-76e5cf13f051",
   "metadata": {},
   "source": [
    "Let's try it out. For \"camiseta\" we hope to see the \"shirt\" metaclass in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571062a-fb2b-491a-8cab-63d1290caa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = get_word_embeddings(aligned_vector_table, \"camiseta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b0ab4-f0a8-45b4-930e-4b053defd8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = aligned_index.search(sv, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac194089-f359-4ffa-98cd-77d5b7eb0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance, idx in zip(D[0],I[0]):\n",
    "    print(f\"{aligned_word_index[idx]}: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b31c1-f440-4404-a061-62dd8d377695",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "Since this didn't work, delete the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71f5bf-22e1-4e04-9c3f-9f4184d1e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddb.delete_table(TableName=aligned_vector_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a9d0d-045c-487f-b706-47e32f88473f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## OPTIONAL Experiment: Using Nova Micro for Multilingual Metaclass Identification\n",
    "Here we show how a small multilingual model can translate products from other languages or even rephrase titles and descriptions so the metaclass identification process can narrow down the categories to search.\n",
    "\n",
    "We initially tried to ask the LLM to select from the full list of metaclass words, but even though the model can technically handle the long list of metaclass words in its context window, the attention mechanism makes it inefficient at doing precise word matching against such a large list. When we ask it to compare against hundreds of words simultaneously, it struggles to maintain precise attention to each word, leading to inconsistent matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d86847-5b51-4110-81e0-c40a00c6a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaclass_words = \"\\n\".join(sorted(word_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0c714-d763-4be0-b5e8-c59740e25a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaclass_prompt_template = '''You are a multilingual retail catalog manager with expertise in product classification across different languages and markets.\n",
    "\n",
    "## BEGIN metaclass words ##\n",
    "{metaclass_words}\n",
    "## END metaclass words ##\n",
    "\n",
    "Product title: {title}\n",
    "\n",
    "Your task is to analyze the product title and identify ALL likely metaclass words, regardless of the title's language. Consider common variants, abbreviations, and multilingual equivalents.\n",
    "\n",
    "<instructions>\n",
    "1. ONLY use metaclass words from the provided list\n",
    "2. Consider regional and linguistic variations in product naming\n",
    "3. Ignore brands, sizes, colors, and other non-category attributes\n",
    "</instructions>\n",
    "\n",
    "Please show your analysis:\n",
    "<thinking>\n",
    "Your step-by-step reasoning here\n",
    "</thinking>\n",
    "\n",
    "Metaclass words (comma-separated):\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f9f22-0a23-4f09-805c-0f48a96e14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Polera estampada de unicornios\"\n",
    "prompt= metaclass_prompt_template.format(title=title, metaclass_words=metaclass_words)\n",
    "messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'text': prompt,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "response = bedrock.converse(\n",
    "    modelId=\"us.amazon.nova-lite-v1:0\",\n",
    "    messages=messages,\n",
    "    inferenceConfig={\n",
    "        'temperature': 0.0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165009f5-6547-4630-a0cf-1f457591e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b909e7-f251-4bfb-92bc-e0846e11574f",
   "metadata": {},
   "source": [
    "We should see the word \"shirt\" in the result. If you run this a few times, you will likely see different results. It doesn't consistently return shirt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39d9a7-4fe4-49f2-bae3-ada74eea426c",
   "metadata": {},
   "source": [
    "Another option is to translate and rephrase the original and follow our normal metaclass identification process looking for exact words and vector matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed41f4d-1a12-452c-9452-dc9425304769",
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrase_prompt_template = '''\n",
    "You are a retail catalog specialist. Your task is to analyze this product and create a simple normalized title that describes what this product fundamentally is.\n",
    "\n",
    "Product title: {title}\n",
    "Product description: {description}\n",
    "\n",
    "Steps:\n",
    "1. Identify the core product type from both title and description\n",
    "2. Remove from consideration:\n",
    "   - Brand names\n",
    "   - Marketing terms\n",
    "   - Decorative elements\n",
    "   - Colors, sizes, materials\n",
    "   - Target audience\n",
    "   - Usage occasions\n",
    "3. Convert to a basic product term\n",
    "\n",
    "##Output format##\n",
    "{{\n",
    "  \"normalized_title\": \"simple normalized title that describes what this product fundamentally is\",\n",
    "}}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c0c84-994a-4677-9f33-f3985709a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Polera estampada de unicornios\"\n",
    "description = \"Esta polera de 100% algodon. Tiene el diseno de un unicornio atravesando un arcoiris.\"\n",
    "prompt= rephrase_prompt_template.format(title=title, description=description)\n",
    "messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'text': prompt,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "response = bedrock.converse(\n",
    "    modelId=\"us.amazon.nova-micro-v1:0\",\n",
    "    messages=messages,\n",
    "    inferenceConfig={\n",
    "        'temperature': 0.0,\n",
    "        'maxTokens': 100,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72caa9-fa8e-4bf9-b774-a875c1c0b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f311b4-e356-4cc9-b937-9c6cb817554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Unicorn T-shirt\"\n",
    "description = \"100% cotton t-shirt. Design: A unicorn jumping through a rainbow.\"\n",
    "prompt= rephrase_prompt_template.format(title=title, description=description)\n",
    "messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'text': prompt,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "response = bedrock.converse(\n",
    "    modelId=\"us.amazon.nova-micro-v1:0\",\n",
    "    messages=messages,\n",
    "    inferenceConfig={\n",
    "        'temperature': 0.0,\n",
    "        'maxTokens': 100,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b4205-f184-4041-a962-87907a7629e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ffa4ce084c7c1",
   "metadata": {},
   "source": [
    "## Media Categories\n",
    "\n",
    "Some product categories, particularly in media (books, movies, games), present unique challenges:\n",
    "\n",
    "1. Their titles often don't contain words that suggest the product type\n",
    "2. They require special handling to ensure accurate categorization\n",
    "\n",
    "By always including these categories in our categorization process, we ensure that media products are correctly identified, even when their titles don't contain typical category keywords.\n",
    "\n",
    "Review the category tree, and make a list of categories to always include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59331794f7a13111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_child_category_ids(cat_ids: list[str]) -> list[str]:\n",
    "    categories = []\n",
    "    for cat_id in cat_ids:\n",
    "        if not category_tree[cat_id][\"childs\"]:\n",
    "            categories.append(cat_id)\n",
    "        else:\n",
    "            categories.extend(get_child_category_ids([child[\"id\"] for child in category_tree[cat_id][\"childs\"]]))\n",
    "    return categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325624c59d09db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "always_category_ids = [\n",
    "    # Classes\n",
    "    \"68040100\",  # Pre-Recorded or Digital Content Media\n",
    "    \"68050100\",  # Audio Visual/Photography Variety Packs\n",
    "    \"65010400\",  # Computer/Video Game Software\n",
    "    \"65010900\",  # Computers/Video Games Variety Packs\n",
    "    \"60010200\",  # Books\n",
    "    \"60010300\",  # Periodicals\n",
    "\n",
    "    # Bricks\n",
    "    \"10001194\",  # GPS Software - Mobile Communications\n",
    "    \"10006237\",  # GPS Software - Mobile Communications - Digital\n",
    "    \"10001197\",  # Mobile Phone Software\n",
    "    \"10006238\",  # Mobile Phone Software - Digital\n",
    "    \"10000624\",  # Cross Segment Variety Packs\n",
    "    \"10002103\",  # Textual/Printed/Reference Materials Variety Packs\n",
    "]\n",
    "always_categories = get_child_category_ids(always_category_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db94c4057603f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(always_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cf99112781489",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Language Adaptation(Optional)\n",
    "\n",
    "To adapt this process for a different language, we need to modify several components. Let's go through the steps you'd need to take."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6a4f916862de0",
   "metadata": {},
   "source": [
    "### 1. Update Stop Words\n",
    "\n",
    "For a new language, you'll need to update the stop words used in text cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282228c19842c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Example: Changing to Spanish stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "spanish_stop_words = set(stopwords.words('spanish'))\n",
    "print(\"Sample of Spanish stop words:\")\n",
    "print(list(spanish_stop_words)[:20])\n",
    "\n",
    "# In the TextCleaner class, you'd update the language and stop words like this:\n",
    "# text_cleaner.language = 'spanish'\n",
    "# text_cleaner._remove_stopwords_tokenize_text = lambda text: ' '.join(\n",
    "#     [w for w in nltk.word_tokenize(text) if w.lower() not in spanish_stop_words]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26a85d7b01892b",
   "metadata": {},
   "source": [
    "### 2. Update Singularization Rules\n",
    "\n",
    "The singularization process is highly language-dependent. For languages other than English, you may need to implement custom singularization logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546442e245edefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Spanish singularization rules (simplified)\n",
    "def spanish_singularize(word):\n",
    "    if word.endswith('es'):\n",
    "        return word[:-2]\n",
    "    elif word.endswith('s'):\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "\n",
    "print(\"Example of Spanish singularization:\")\n",
    "print(spanish_singularize(\"gatos\"))  # Should print \"gato\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8352aeb67be8ce7d",
   "metadata": {},
   "source": [
    "### 3. Update Synonyms and Descriptors\n",
    "\n",
    "Synonyms and descriptors need to be updated for the new language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd6ad5507198ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Spanish synonyms and descriptors\n",
    "spanish_synonyms = {\n",
    "    \"ordenador\": \"computadora\",\n",
    "    \"movil\": \"celular\"\n",
    "}\n",
    "\n",
    "spanish_descriptors = [\n",
    "    \"nuevo\", \"grande\", \"pequeno\"\n",
    "]\n",
    "\n",
    "print(\"Example Spanish synonyms:\", spanish_synonyms)\n",
    "print(\"Example Spanish descriptors:\", spanish_descriptors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5ee763c7e0180",
   "metadata": {},
   "source": [
    "### 4. Word Embeddings for Different Languages\n",
    "\n",
    "For the metaclass identification process, you'll need word embeddings in the target language. You can find pre-trained word embeddings for many languages on the [FastText website](https://fasttext.cc/docs/en/crawl-vectors.html).\n",
    "\n",
    "```\n",
    "# Example of loading Spanish word embeddings (you would need to download these first)\n",
    "# spanish_embeddings_file = 'path_to_spanish_embeddings.vec'\n",
    "# spanish_wordvectors = KeyedVectors.load_word2vec_format(spanish_embeddings_file)\n",
    "\n",
    "# print(\"Example of Spanish word vector:\")\n",
    "# print(spanish_wordvectors['gato'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da521c7d254ea45",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "After adapting these components for your target language:\n",
    "\n",
    "1. Re-run the category name analysis with the new language settings.\n",
    "2. Generate new metaclasses based on the cleaned category names in the target language.\n",
    "3. Use the language-specific word embeddings for further processing and analysis.\n",
    "\n",
    "Remember to thoroughly test the adapted system with a sample of product data in the target language to ensure it's performing as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d49e11c6394396",
   "metadata": {},
   "source": [
    "## Persist Categories and Configuration\n",
    "\n",
    "Persisting our prepared data and configurations is a critical step.\n",
    "\n",
    "By storing this data in S3 and configuration paths in SSM Parameter Store, we create a flexible, scalable foundation for our categorization system.\n",
    "\n",
    "Upload needed files to the configuration S3 bucket created in the CDK deployment and save the paths in SSM parameter store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95489962d123750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(unique_leaves.keys(), columns=['name'])\n",
    "df_words.to_json('data/metaclasses.json')\n",
    "df_words.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756b7f0088c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_df.to_json('data/mappings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a45f311e97a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_set(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb752c068d2d3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/word_map.json\", \"w\") as f:\n",
    "    json.dump(word_map, f, default=encode_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ced2a-bb70-40a5-bc0f-6e1c3c1ca146",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/category_vectors.json\", \"w\") as f:\n",
    "    json.dump(category_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f0a6fabb07c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/marcas.json', 'w') as f:\n",
    "    json.dump(brands, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1d90aa5ef9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/singularize.json\", \"w\") as f:\n",
    "    json.dump(singularize_exceptions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed40b6ca140bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/descriptors.json\", \"w\") as f:\n",
    "    json.dump(descriptors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f946cc37190d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/synonyms.json\", \"w\") as f:\n",
    "    json.dump(synonyms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729e8d8c56d4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/always.json\", \"w\") as f:\n",
    "    json.dump(always_categories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed414b2445478e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_bucket = ssm.get_parameter(Name=f\"{ssm_prefix}ConfigurationBucket\")['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2560eff0d49e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp data/labelcats.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/metaclasses.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/mappings.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/word_map.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/marcas.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/singularize.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/synonyms.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/descriptors.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/always.json s3://{config_bucket}/data/\n",
    "!aws s3 cp data/category_vectors.json s3://{config_bucket}/data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b476085f6cf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm.put_parameter(\n",
    "    Name=f\"{ssm_prefix}CategorizationConfig\",\n",
    "    Value=json.dumps({\n",
    "        \"language\": language,\n",
    "        \"wordEmbeddingsTable\": vector_table_name,\n",
    "        \"categoryTree\": \"data/labelcats.json\",\n",
    "        \"metaclasses\": \"data/metaclasses.json\",\n",
    "        \"mappings\": \"data/mappings.json\",\n",
    "        \"categoryVectors\": \"data/category_vectors.json\",\n",
    "        \"wordMap\": \"data/word_map.json\",\n",
    "        \"brands\": \"data/marcas.json\",\n",
    "        \"singularize\": \"data/singularize.json\",\n",
    "        \"synonyms\": \"data/synonyms.json\",\n",
    "        \"descriptors\": \"data/descriptors.json\",\n",
    "        \"alwaysCategories\": \"data/always.json\",\n",
    "    }),\n",
    "    Type=\"String\",\n",
    "    Overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6148d5709cff140a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has guided you through the process of generating metaclasses from a category tree and adapting the process for different languages. Key steps included:\n",
    "\n",
    "1. Loading and analyzing the category tree\n",
    "2. Preparing and refining text cleaning configurations\n",
    "3. Generating metaclasses from cleaned category names\n",
    "4. Outlining the process for adapting to different languages\n",
    "\n",
    "By following these steps and iterating as needed, you can create a robust system for categorizing products in your language and market."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
